# Machine-Learning-Projects
Solved end-to-end machine learning projects

## [All State Insurance Claims Severity Prediction](https://github.com/shejz/Machine-Learning-Projects/tree/master/All%20State%20Insurance%20Claims%20Severity%20Prediction) [![Nbviewer](https://github.com/jupyter/design/blob/master/logos/Badges/nbviewer_badge.svg)](https://nbviewer.jupyter.org/github/shejz/Machine-Learning-Projects/blob/master/All%20State%20Insurance%20Claims%20Severity%20Prediction/All%20State%20Insurance%20Claims%20Severity%20Prediction.ipynb)

In this data science project, you will develop automated methods for predicting the cost, and severity of insurance claims.

**Description**:

When you've been devastated by a serious car accident, your focus is on the things that matter the most: family, friends, and other loved ones. Pushing paper with your insurance agent is the last place you want your time or mental energy spent. This is why Allstate, a personal insurer in the United States, is continually seeking fresh ideas to improve their claims service for the over 16 million households they protect.

- Basic exploratory analysis using the claims data
- Insights from exploratory data analysis
- Factors to be considered for claims processing and severity prediction
- Implementation of the model using R
- Building smarter predictive models including **XGBoost**

## [Build an Image Classifier for Plant Species Identification](https://github.com/shejz/Machine-Learning-Projects/tree/master/Build%20an%20Image%20Classifier%20for%20Plant%20Species%20Identification)[![Nbviewer](https://github.com/jupyter/design/blob/master/logos/Badges/nbviewer_badge.svg)](https://nbviewer.jupyter.org/github/shejz/Machine-Learning-Projects/blob/master/Build%20an%20Image%20Classifier%20for%20Plant%20Species%20Identification/Build%20an%20Image%20Classifier%20for%20Plant%20Species%20Identification.ipynb)

In this machine learning project, we will use binary leaf images and extracted features, including shape, margin, and texture to accurately identify plant species using different benchmark classification techniques.

**Description**:

The objective of this machine learning project is to use binary leaf images and extracted features, including shape, margin, and texture, to accurately identify 99 species of plants. Leaves, due to their volume, prevalence, and unique characteristics, are an effective means of differentiating plant species. They also provide a fun introduction to applying techniques that involve image-based features. We are going to apply different classification techniques to benchmark the relevance of classifiers in image classification problem.

- Image Processing
- Feature selection
- Classifier comparison
- Benchmarking
- Prediction


## [Choosing the right Time Series Forecasting Methods](https://github.com/shejz/Machine-Learning-Projects/tree/master/Choosing%20the%20right%20Time%20Series%20Forecasting%20Methods)[![Nbviewer](https://github.com/jupyter/design/blob/master/logos/Badges/nbviewer_badge.svg)](https://nbviewer.jupyter.org/github/shejz/Machine-Learning-Projects/blob/master/Choosing%20the%20right%20Time%20Series%20Forecasting%20Methods/Time-Series-Forecasting.ipynb)

There are different time series forecasting methods to forecast stock price, demand etc. In this machine learning project, you will learn to determine which forecasting method to be used when and how to apply with time series forecasting example.

**Description**:

In this machine learning project, we will be taking open source datasets that are publicly available and will be discussing various methods/techniques of performing time series forecasting. We will discuss about the traditional methods such as holt-winters method, Autoregressive integrated moving average method, exponential smoothing methods, as well we will also be comparing the modern methods of performing forecasting using neural network based models.

- Understanding the importance of time series
- Understanding the mathematics of time series
- Discussion about methods/techniques
- Application of the models using R or Python
- Making conclusions

## [Credit Card Fraud Detection as a Classification Problem](https://github.com/shejz/Machine-Learning-Projects/tree/master/Credit%20Card%20Fraud%20Detection%20as%20a%20Classification%20Problem)[![Nbviewer](https://github.com/jupyter/design/blob/master/logos/Badges/nbviewer_badge.svg)](https://nbviewer.jupyter.org/github/shejz/Machine-Learning-Projects/blob/master/Credit%20Card%20Fraud%20Detection%20as%20a%20Classification%20Problem/Credit%20Card%20Fraud%20Detection%20as%20a%20Classification%20Problem.ipynb) 
In this data science project, we will predict the credit card fraud in the transactional dataset using some of the predictive models.

- Handle imbalance data
- Creation classifier
- Compare accuracy
- Use deep learning to classify
- Implementation using R

The Credit Card Fraud detection Dataset contains transactions made by credit cards in September 2013 by European cardholders. This dataset present transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.

The dataset has been collected and analyzed during a research collaboration of Worldline and the [Machine Learning Group](http://mlg.ulb.ac.be) of ULB (Université Libre de Bruxelles) on big data mining and fraud detection. More details on current and past projects on related topics are available on http://mlg.ulb.ac.be/BruFence and http://mlg.ulb.ac.be/ARTML

## [Identifying Product Bundles from Sales Data Using R Language](https://github.com/shejz/Machine-Learning-Projects/tree/master/Identifying%20Product%20Bundles%20from%20Sales%20Data)


**Description**:

The weekly sales transaction dataset consists of weekly purchased quantities of 800 products over 52 weeks. Normalised values are provided too. The objective of this data science project in R is to find out product bundles that can be put together on sale. Typically Market Basket Analysis was used to identify such bundles, here we are going to compare the relative importance of time series clustering in identifying product bundles.

- Time series clustering
- K-means
- HC- clustering
- Model Based clustering
- Comparison of clustering

## [Instacart Market Basket Analysis](https://github.com/shejz/Machine-Learning-Projects/tree/master/Instacart%20Market%20Basket%20Analysis)[![Nbviewer](https://github.com/jupyter/design/blob/master/logos/Badges/nbviewer_badge.svg)](https://nbviewer.jupyter.org/github/shejz/Machine-Learning-Projects/blob/master/Instacart%20Market%20Basket%20Analysis/Instacart%20Market%20Basket%20Analysis.ipynb) 
Build a recommendation engine which will predict the products to be purchased by an Instacart consumer again.

- Read data from large size files
- Perform Exploratory Data Analysis (EDA)
- Apply logic to derive insights
- Create association rule model
- Implementation using R

**Description**:

Whether you shop from meticulously planned grocery lists or let whimsy guide your grazing, our unique food rituals define who we are. Instacart, a grocery ordering and delivery app aim to make it easy to fill your refrigerator and pantry with your personal favorites and staples when you need them. After selecting products through the Instacart app, personal shoppers review your order and do the in-store shopping and delivery for you.

Instacart’s data science team plays a big part in providing this delightful shopping experience. Currently, they use transactional data to develop models that predict which products a user will buy again, try for the first time, or add to their cart next during a session. Recently, Instacart open-sourced this data - see their blog post on 3 Million Instacart Orders (https://tech.instacart.com/3-million-instacart-orders-open-sourced-d40d29ead6f2), Open Sourced.

In this data science project, we are going to use this anonymized data on customer orders over time to predict which previously purchased products will be in a user's next order.

## [Music Recommendation System Project using Python and R](https://github.com/shejz/Machine-Learning-Projects/tree/master/Music%20Recommendation%20System%20Project%20using%20Python%20and%20R)[![Nbviewer](https://github.com/jupyter/design/blob/master/logos/Badges/nbviewer_badge.svg)](https://nbviewer.jupyter.org/github/shejz/Machine-Learning-Projects/blob/master/Music%20Recommendation%20System%20Project%20using%20Python%20and%20R/Perform%20EDA%20and%20build%20Music%20Recommendation%20Engine.ipynb)
Work with KKBOX's Music Recommendation System dataset to build the best music recommendation engine.

**Description**:

The 11th ACM International Conference on Web Search and Data Mining (WSDM 2018) is challenging you to build a better music recommendation system using a donated dataset from KKBOX. WSDM (pronounced "wisdom") is one of the the premier conferences on web inspired research involving search and data mining. They're committed to publishing original, high quality papers and presentations, with an emphasis on practical but principled novel models. They currently use a collaborative filtering based algorithm with matrix factorization and word embedding in their recommendation system but believe new machine learning techniques could lead to better results.

In this machine learning project, you will be asked to predict the chances of a user listening to a song repetitively after the first observable listening event within a time window was triggered. If there are recurring listening event(s) triggered within a month after the user's very first observable listening event, its target is marked 1, and 0 otherwise in the training set. The same rule applies to the testing set.

KKBOX provides a music dataset that consists of information of the first observable listening event for each unique user-song pair within a specific time duration. Metadata of each unique user and song pair is also provided. The use of public data to increase the level of accuracy of your prediction is encouraged.

The train and the test data are selected from users listening history in a given time period. Note that this time period is chosen to be before the WSDM-KKBox Churn Prediction time period. The train and test sets are split based on time, and the split of public/private is based on unique user/song pairs.

- Working with Music Data with several category
- EDA using several Visualization techniques
- Building Automated Recommendation Engine
- Solve this use case using Python and R
- Finding Parameter Tuning for better Algorithm

## [Perform Time series modelling using Facebook Prophet](https://github.com/shejz/Machine-Learning-Projects/tree/master/Perform%20Time%20series%20modelling%20using%20Facebook%20Prophet)[![Nbviewer](https://github.com/jupyter/design/blob/master/logos/Badges/nbviewer_badge.svg)](https://nbviewer.jupyter.org/github/shejz/Machine-Learning-Projects/blob/master/Perform%20Time%20series%20modelling%20using%20Facebook%20Prophet/Benchmarking%20ARIMA%20vs%20Prophet%20vs%20Keras.ipynb) 
In this project, we are going to talk about Time Series Forecasting to predict the electricity requirement for a particular house using Prophet.

**Description**:

There are various methods to perform time series forecasting. Traditionally people have used AR, MA or ARIMA based models to perform forecasting. Prophet is an open source forecasting tool built by Facebook. It can be used for time series modeling and forecasting trends in the future. The advantage of using Prophet over traditional libraries is that one does not need to know the technicalities of time series, domain knowledge is not really required to do time series forecasting. In this Hackerday we are going to use Prophet vs other methods to do the benchmarking.

- Time series forecasting using ARIMA
- Time series forecasting using Prophet
- Implementing Prophet
- Knowing advantages of Prophet
- Using Bayesian Method of forecasting























