{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/root/hackerday/12_employee_access_need/train.csv\n",
    "/root/hackerday/12_employee_access_need/test.csv\n",
    "/root/hackerday/12_employee_access_need/sampleSubmission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import the dataset\n",
    "#Perform Univariate Analysis\n",
    "#Data Transformation conversion\n",
    "#prepare model data\n",
    "#select model\n",
    "#apply model\n",
    "#evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ACTION  RESOURCE  MGR_ID  ROLE_ROLLUP_1  ROLE_ROLLUP_2  ROLE_DEPTNAME  \\\n",
      "0       1     39353   85475         117961         118300         123472   \n",
      "1       1     17183    1540         117961         118343         123125   \n",
      "2       1     36724   14457         118219         118220         117884   \n",
      "3       1     36135    5396         117961         118343         119993   \n",
      "4       1     42680    5905         117929         117930         119569   \n",
      "\n",
      "   ROLE_TITLE  ROLE_FAMILY_DESC  ROLE_FAMILY  ROLE_CODE  \n",
      "0      117905            117906       290919     117908  \n",
      "1      118536            118536       308574     118539  \n",
      "2      117879            267952        19721     117880  \n",
      "3      118321            240983       290919     118322  \n",
      "4      119323            123932        19793     119325  \n"
     ]
    }
   ],
   "source": [
    "trdata = pd.read_csv(\"/root/hackerday/12_employee_access_need/train.csv\")\n",
    "print trdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118300    4424\n",
       "118343    3945\n",
       "118327    2641\n",
       "118225    2547\n",
       "118386    1796\n",
       "Name: ROLE_ROLLUP_2, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trdata['ROLE_ROLLUP_2'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc49e630090>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEbCAYAAAAh9sTfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJtykAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc49e680fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trdata['MGR_ID'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from sklearn import metrics, linear_model\n",
    "from sklearn.cross_validation import KFold\n",
    "from scipy import sparse\n",
    "from itertools import combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dict_encode(encoding, value):\n",
    "    if not value in encoding:\n",
    "        encoding[value] = {'code': len(encoding)+1, 'count': 0}\n",
    "    enc = encoding[value]\n",
    "    enc['count'] += 1\n",
    "    encoding[value] = enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dict_decode(encoding, value, min_occurs):\n",
    "    enc = encoding[value]\n",
    "    if enc['count'] < min_occurs:\n",
    "        return -1\n",
    "    else:\n",
    "        return enc['code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def group_data(data, degree, min_occurs):\n",
    "    \"\"\" \n",
    "    numpy.array -> numpy.array\n",
    "    \n",
    "    Groups all columns of data into all combinations of degree\n",
    "    \"\"\"\n",
    "    m, n = data.shape\n",
    "    encoding = dict()\n",
    "    for indexes in combinations(range(n), degree):\n",
    "        for v in data[:, indexes]:\n",
    "            dict_encode(encoding, tuple(v))\n",
    "    new_data = []\n",
    "    for indexes in combinations(range(n), degree):\n",
    "        new_data.append([dict_decode(encoding, tuple(v), min_occurs) for v in data[:, indexes]])\n",
    "    return array(new_data).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encoder(data, keymap=None):\n",
    "    \"\"\"\n",
    "     one_hot_encoder takes data matrix with categorical columns and\n",
    "     converts it to a sparse binary matrix.\n",
    "     \n",
    "     Returns sparse binary matrix and keymap mapping categories to indicies.\n",
    "     If a keymap is supplied on input it will be used instead of creating one\n",
    "     and any categories appearing in the data that are not in the keymap are\n",
    "     ignored\n",
    "     \"\"\"\n",
    "    if keymap is None:\n",
    "        keymap = []\n",
    "        for col in data.T:\n",
    "            uniques = set(list(col))\n",
    "            keymap.append(dict((key, i) for i, key in enumerate(uniques)))\n",
    "    total_pts = data.shape[0]\n",
    "    outdat = []\n",
    "    for i, col in enumerate(data.T):\n",
    "        km = keymap[i]\n",
    "        num_labels = len(km)\n",
    "        spmat = sparse.lil_matrix((total_pts, num_labels))\n",
    "        for j, val in enumerate(col):\n",
    "            if val in km:\n",
    "                spmat[j, km[val]] = 1\n",
    "        outdat.append(spmat)\n",
    "    outdat = sparse.hstack(outdat).tocsr()\n",
    "    return outdat, keymap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_test_submission(filename, prediction):\n",
    "    content = ['id,ACTION']\n",
    "    for i, p in enumerate(prediction):\n",
    "        content.append('%i,%f' % (i + 1, p))\n",
    "    f = open(filename, 'w')\n",
    "    f.write('\\n'.join(content))\n",
    "    f.close()\n",
    "    print('Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_loop(X, y, model, N, seed):\n",
    "    mean_auc = 0.\n",
    "    k_fold = KFold(len(y), N, indices=True, shuffle=True,\n",
    "                   random_state=seed)\n",
    "    for train_ix, test_ix in k_fold:\n",
    "        model.fit(X[train_ix], y[train_ix])\n",
    "        preds = model.predict_proba(X[test_ix])[:, 1]\n",
    "        auc = metrics.auc_score(y[test_ix], preds)\n",
    "        #print(\"AUC (fold %d/%d): %f\" % (i + 1, N, auc))\n",
    "        mean_auc += auc\n",
    "    return mean_auc / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'submit': 'lr/data.lr.11.1.test.pred.csv', 'train': '-f', 'good_features': None, 'test': '/home/ubuntu/.local/share/jupyter/runtime/kernel-404c5bd7-dfd1-418d-a845-1a214ec43e49.json', 'seed': 123, 'min_occurs': 3}\n",
      "Reading train dataset...\n",
      "Reading test dataset...\n",
      "Transforming data (32769 instances)..."
     ]
    }
   ],
   "source": [
    "def main(train, test, submit, seed, min_occurs, good_features):\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(\"Reading train dataset...\")\n",
    "    train_data = pd.read_csv(\"/root/hackerday/12_employee_access_need/train.csv\")\n",
    "    #print(train_data.head())\n",
    "\n",
    "    print(\"Reading test dataset...\")\n",
    "    test_data = pd.read_csv(\"/root/hackerday/12_employee_access_need/test.csv\")\n",
    "    #print(test_data.head())\n",
    "\n",
    "    all_data = np.vstack((train_data.ix[:, 1:], test_data.ix[:, 1:]))\n",
    "\n",
    "    num_train = np.shape(train_data)[0]\n",
    "    # Transform data\n",
    "    print(\"Transforming data (%i instances)...\" % num_train)\n",
    "    d_2 = group_data(all_data, degree=2, min_occurs=min_occurs)\n",
    "    d_3 = group_data(all_data, degree=3, min_occurs=min_occurs)\n",
    "    d_4 = group_data(all_data, degree=4, min_occurs=min_occurs)\n",
    "    d_5 = group_data(all_data, degree=5, min_occurs=min_occurs)\n",
    "    d_6 = group_data(all_data, degree=6, min_occurs=min_occurs)\n",
    "    d_7 = group_data(all_data, degree=7, min_occurs=min_occurs)\n",
    "\n",
    "    y = array(train_data.ACTION)\n",
    "    #X_train_all = np.hstack((all_data[:num_train], d_2[:num_train], d_3[:num_train],\n",
    "    #                         d_4[:num_train], d_7[:num_train]))\n",
    "    #X_test_all = np.hstack((all_data[num_train:], d_2[num_train:], d_3[num_train:],\n",
    "    #                        d_4[num_train:], d_7[num_train:]))\n",
    "    X_train_all = np.hstack((all_data[:num_train], d_2[:num_train], d_3[:num_train], d_4[:num_train],\n",
    "                             d_5[:num_train], d_6[:num_train], d_7[:num_train]))\n",
    "    X_test_all = np.hstack((all_data[num_train:], d_2[num_train:], d_3[num_train:], d_4[num_train:],\n",
    "                            d_5[num_train:], d_6[num_train:], d_7[num_train:]))\n",
    "    num_features = X_train_all.shape[1]\n",
    "    print(\"Total number of categorical features %i\" % num_features)\n",
    "\n",
    "    rnd = random.Random()\n",
    "    rnd.seed(seed*num_features)\n",
    "\n",
    "    model = linear_model.LogisticRegression()\n",
    "    model.C = 0.5 + rnd.random()*3.5\n",
    "    print(\"Logistic C parameter: %f\" % model.C)\n",
    "\n",
    "    # Xts holds one hot encodings for each individual feature in memory\n",
    "    # speeding up feature selection \n",
    "    Xts = [one_hot_encoder(X_train_all[:, [i]])[0] for i in range(num_features)]\n",
    "\n",
    "    print(\"Performing aproximate greedy feature selection...\")\n",
    "    N = 10\n",
    "    if good_features is None:\n",
    "        score_hist = []\n",
    "        good_features = set([])\n",
    "\n",
    "        # Feature selection loop\n",
    "        f_remain = range(len(Xts))\n",
    "        cur_best_score = -1\n",
    "        cur_best_score_thres = 1.0\n",
    "        while len(score_hist) < 2 or score_hist[-1][0] > score_hist[-2][0]:\n",
    "            scores = []\n",
    "            f_shuff = list(f_remain)\n",
    "            rnd.shuffle(f_shuff)\n",
    "            n_thres = 0.3679*len(f_remain)\n",
    "            i = 0\n",
    "            iter_best_score = -1\n",
    "            for f in f_shuff:\n",
    "\n",
    "                i += 1\n",
    "                feats = list(good_features) + [f]\n",
    "                Xt = sparse.hstack([Xts[j] for j in feats]).tocsr()\n",
    "                score = cv_loop(Xt, y, model, N, seed)\n",
    "                if score < (cur_best_score*cur_best_score_thres):\n",
    "                    f_remain.remove(f)\n",
    "                    print(\"Discarded: %i (AUC = %f) \" % (f, score))\n",
    "                else:\n",
    "                    scores.append((score, f))\n",
    "                    if score > iter_best_score:\n",
    "                        iter_best_score = score\n",
    "                        if i > n_thres and iter_best_score > cur_best_score:\n",
    "                            print(\"Early stop on iter %i\" % i)\n",
    "                            break\n",
    "            if len(scores) > 0:\n",
    "                best_score = sorted(scores)[-1]\n",
    "                f_remain.remove(best_score[1])\n",
    "                if best_score[0] > cur_best_score:\n",
    "                    good_features.add(best_score[1])\n",
    "                    score_hist.append(best_score)\n",
    "                    cur_best_score = best_score[0]\n",
    "                print(\"Current features: %s (AUC = %f, remain = %i) \" %\n",
    "                      (list(good_features), best_score[0], len(f_remain)))\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    good_features = sorted(list(good_features))\n",
    "    print(\"Selected features %s\" % good_features)\n",
    "\n",
    "    print(\"Performing hyperparameter selection...\")\n",
    "    # Hyperparameter selection loop\n",
    "    Xt = sparse.hstack([Xts[j] for j in good_features]).tocsr()\n",
    "    score_hist = []\n",
    "    score = cv_loop(Xt, y, model, N, seed)\n",
    "    score_hist.append((score, model.C))\n",
    "    \n",
    "    Cvals = np.logspace(-3, 4, 20, base=2)\n",
    "    for C in Cvals:\n",
    "        model.C = C\n",
    "        score = cv_loop(Xt, y, model, N, seed)\n",
    "        score_hist.append((score, C))\n",
    "        print(\"C: %f Mean AUC: %f\" % (C, score))\n",
    "    model.C = sorted(score_hist)[-1][1]\n",
    "    score = sorted(score_hist)[-1][0]\n",
    "    print(\"Best (C, AUC): (%f, %f)\" % (model.C, score))\n",
    "\n",
    "    print(\"Performing One Hot Encoding on entire dataset...\")\n",
    "    Xt = np.vstack((X_train_all[:, good_features], X_test_all[:, good_features]))\n",
    "    Xt, keymap = one_hot_encoder(Xt)\n",
    "    X_train = Xt[:num_train]\n",
    "    X_test = Xt[num_train:]\n",
    "\n",
    "    print(\"Training full model...\")\n",
    "    model.fit(X_train, y)\n",
    "\n",
    "    print(\"Making prediction and saving results...\")\n",
    "    preds = model.predict_proba(X_test)[:, 1]\n",
    "    create_test_submission(submit, preds)\n",
    "    print(\"Total time %f minutes\" % ((time.time() - start_time)/60.0))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    name_def = '11.1'\n",
    "    args = {'train': 'lr/data.lr.' + name_def + '.tr.csv',\n",
    "            'test': 'lr/data.lr.' + name_def + '.test.csv',\n",
    "            'submit': 'lr/data.lr.' + name_def + '.test.pred.csv',\n",
    "            'seed': 123,\n",
    "            'min_occurs': 3,\n",
    "            'good_features': []}\n",
    "    if len(sys.argv) >= 2:\n",
    "        args['train'] = sys.argv[1]\n",
    "\n",
    "    if len(sys.argv) >= 3:\n",
    "        args['test'] = sys.argv[2]\n",
    "\n",
    "    if len(sys.argv) >= 4:\n",
    "        args['submit'] = sys.argv[3]\n",
    "\n",
    "    if len(sys.argv) >= 5:\n",
    "        args['seed'] = int(sys.argv[4])\n",
    "\n",
    "    if len(sys.argv) >= 6:\n",
    "        args['min_occurs'] = int(sys.argv[5])\n",
    "\n",
    "    if len(sys.argv) >= 7:\n",
    "        args['good_features'] = [int(val) for val in sys.argv[6].split(',')]\n",
    "\n",
    "    if len(args['good_features']) == 0:\n",
    "        args['good_features'] = None\n",
    "\n",
    "    print(args)\n",
    "    main(**args)\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
